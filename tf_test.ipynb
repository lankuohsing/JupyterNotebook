{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os as os\n",
    "from PIL import Image as im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sparse_to_dense in module tensorflow.python.ops.sparse_ops:\n",
      "\n",
      "sparse_to_dense(sparse_indices, output_shape, sparse_values, default_value=0, validate_indices=True, name=None)\n",
      "    Converts a sparse representation into a dense tensor.\n",
      "    \n",
      "    Builds an array `dense` with shape `output_shape` such that\n",
      "    \n",
      "    ```python\n",
      "    # If sparse_indices is scalar\n",
      "    dense[i] = (i == sparse_indices ? sparse_values : default_value)\n",
      "    \n",
      "    # If sparse_indices is a vector, then for each i\n",
      "    dense[sparse_indices[i]] = sparse_values[i]\n",
      "    \n",
      "    # If sparse_indices is an n by d matrix, then for each i in [0, n)\n",
      "    dense[sparse_indices[i][0], ..., sparse_indices[i][d-1]] = sparse_values[i]\n",
      "    ```\n",
      "    \n",
      "    All other values in `dense` are set to `default_value`.  If `sparse_values`\n",
      "    is a scalar, all sparse indices are set to this single value.\n",
      "    \n",
      "    Indices should be sorted in lexicographic order, and indices must not\n",
      "    contain any repeats. If `validate_indices` is True, these properties\n",
      "    are checked during execution.\n",
      "    \n",
      "    Args:\n",
      "      sparse_indices: A 0-D, 1-D, or 2-D `Tensor` of type `int32` or `int64`.\n",
      "        `sparse_indices[i]` contains the complete index where `sparse_values[i]`\n",
      "        will be placed.\n",
      "      output_shape: A 1-D `Tensor` of the same type as `sparse_indices`.  Shape\n",
      "        of the dense output tensor.\n",
      "      sparse_values: A 0-D or 1-D `Tensor`.  Values corresponding to each row of\n",
      "        `sparse_indices`, or a scalar value to be used for all sparse indices.\n",
      "      default_value: A 0-D `Tensor` of the same type as `sparse_values`.  Value\n",
      "        to set for indices not specified in `sparse_indices`.  Defaults to zero.\n",
      "      validate_indices: A boolean value.  If True, indices are checked to make\n",
      "        sure they are sorted in lexicographic order and that there are no repeats.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      Dense `Tensor` of shape `output_shape`.  Has the same type as\n",
      "      `sparse_values`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.sparse_to_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fun():\n",
    "    x=xx*2\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(fun())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pathDir=os.listdir('D:/Dataset_for_dl/MNIST图片库/trainimage/pic2/0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/Dataset_for_dl/MNIST图片库/trainimage/pic2/0/1.bmp'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "child=os.path.join('%s%s' % ('D:/Dataset_for_dl/MNIST图片库/trainimage/pic2/0/','1.bmp'))\n",
    "child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "embedded null character",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-8f578c33321c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:\\Dataset_for_dl\\MNIST图片库\\trainimage\\pic2\\0\\1.bmp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mD:\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2278\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2279\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2280\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: embedded null character"
     ]
    }
   ],
   "source": [
    "img=im.open('D:\\Dataset_for_dl\\MNIST图片库\\trainimage\\pic2\\0\\1.bmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "child2='/Dataset_for_dl/MNIST图片库/'+'trainimage'+'/pic2/'+'0'+'/'+'1.bmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAACS0lEQVR4nO2WPWsqURCG51gohO3E\nQtiUSRdYVhAFIaWFKTU/JJAiVqKFlYV2VoKwWNmsnUXIhySQJnYpzSIRt/ADrIQZ31spyI26mxsC\ngTswzew785xzZgZWERHoBy3wk7D/wIMWi8Wo0WiQiFCj0SDTND3l4StuGAam0ymYeeOTycRLrn9Y\nPB7HcDiEiICZMZvN4LoumBnJZBLBYPB7gEdHR0ilUnh/fwczb4AvLy/IZrObWD6f31nDVw/r9Trd\n3d2RrutbcdM0SdM0ur+/JyKis7OznTU8A2OxGGUyGVJKkVKKHh4e6Pr6mpRSNB6P6fX1lWq1GgUC\nAVJK7a3le0A6nQ40TUMmk8HNzQ0ikchGKyJYLBYwTfNrPTw9PYVlWRARuK6Lfr+PbDa7U7/uq2VZ\n/oGhUAi2bYOZMZ/PkU6nEQ6Hoev6QeDj46N/YDKZ3Dzj+fm5p0n+J+DT0xNEBLe3t55XBwBEBL1e\nz99aXFxckGEYBIBs294l+8tWqxUBoH6/v1Pz6UlyuRyYGaPRCNFo9ODNQqEQyuUyRATdbheapvl7\n0jVwMBh4gpVKJTAzHMdBOp3ep98PrFare2GGYcCyLDAz2u22lz5//uHy8hIiAsdxdiZfXV1hOp1C\nRNBsNr0O1v4bLpdL1Go1GIaB4+Nj5HI52LYNx3EgIhgMBmi1WkgkEt8DXPvHxwfe3t62Yr1eD8Vi\n0fPK7AXquo7n5+dN8fVCMzNc1z3YW99AIkI0GkWhUNgCVioVnJycfBUGtab+lP2uv7ZfAfwDsWIL\nOapa3XEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=28x28 at 0xAF77630>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=np.array([[ 0.87224406,0.01501547,0.31577358,-0.64266002,-0.10089301]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b=np.array([[ 0.02016388],\n",
    "   [-0.40775889],\n",
    "   [-1.21996999],\n",
    "   [-0.72827661],\n",
    "   [ 1.3605175 ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0430016]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "b=np.array([[5,6],[7,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 22],\n",
       "       [43, 50]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3136, 1024]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=tf.Variable(tf.random_normal([7*7*64,1024]))\n",
    "a.get_shape().as_list()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
